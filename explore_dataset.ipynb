{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the RealImpact dataset\n",
    "\n",
    "The `dataset` directory is expected to have been generated with:\n",
    "```shell\n",
    "$ cd dataset\n",
    "$ bash download.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from os import listdir\n",
    "from os.path import join, isdir\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DatasetPath = 'dataset/'\n",
    "DatasetNames = sorted([d for d in listdir(DatasetPath) if isdir(join(DatasetPath, d))])\n",
    "M = len(DatasetNames)\n",
    "\n",
    "print(\"M = {}\".format(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_directory = widgets.Dropdown(\n",
    "    value='60_SkullCup',\n",
    "    description='Dataset:',\n",
    "    options=DatasetNames,\n",
    ")\n",
    "\n",
    "# These globals always reflect the most recently selected dataset.\n",
    "ObjectName = \"\"\n",
    "ObjectPath = \"\"\n",
    "ObjectFiles = []\n",
    "\n",
    "def set_object(object_name):\n",
    "    global ObjectName, ObjectPath, ObjectFiles\n",
    "    ObjectName = object_name\n",
    "    ObjectPath = join(DatasetPath, object_name, \"preprocessed\")\n",
    "    ObjectFiles = sorted(listdir(ObjectPath))\n",
    "    values_formatted = json.dumps(\n",
    "        {\n",
    "            \"ObjectPath\": ObjectPath,\n",
    "            \"ObjectFiles\": ObjectFiles,\n",
    "        },\n",
    "        indent=4,\n",
    "    )\n",
    "    # Surround variable names with backticks instead of quotes.\n",
    "    values_formatted = re.sub('\\\"(.*)\\\"\\: (.*)', r'`\\1`: \\2', values_formatted)\n",
    "    print(\"New object selected. Updated globals:\\n{}\".format(values_formatted))\n",
    "\n",
    "def on_dataset_directory_change(event):\n",
    "    if event['type'] == 'change' and event['name'] == 'value':\n",
    "        set_object(event['new'])\n",
    "\n",
    "\n",
    "select_directory.observe(on_dataset_directory_change)\n",
    "set_object(select_directory.value)\n",
    "\n",
    "select_directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected `ObjectFiles` value:\n",
    "```\n",
    "[ \n",
    "    \"angle.npy\",\n",
    "    \"deconvolved_0db.npy\",\n",
    "    \"distance.npy\",\n",
    "    \"listenerXYZ.npy\",\n",
    "    \"material_0.mtl\"\n",
    "    \"material_0.png\",\n",
    "    \"micID.npy\",\n",
    "    \"transformed.obj\",\n",
    "    \"vertexID.npy\",\n",
    "    \"vertexXYZ.npy\",\n",
    "]\n",
    "```\n",
    "\n",
    "`PreprocessedFiles` is expected to contain the above file names for any chosen dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `transformed.obj` / `vertexID.npy` / `vertexXYZ.npy` / `material_0.png`\n",
    "\n",
    "Visualize the object mesh and impact vertex using [trimesh](https://github.com/mikedh/trimesh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ids = np.load(join(ObjectPath, \"vertexID.npy\")) \n",
    "vertex_xyzs = np.load(join(ObjectPath, \"vertexXYZ.npy\")) \n",
    "\n",
    "print(f\"`vertex_ids`:\\n\\tshape: {vertex_ids.shape}\\n\\t{len(np.unique(vertex_ids))} unique values: {np.unique(vertex_ids)}\")\n",
    "display(vertex_ids)\n",
    "\n",
    "print(f\"`vertex_xyzs`:\\n\\tshape: {vertex_xyzs.shape}\\n\\t{len(np.unique(vertex_xyzs))} unique values.\")\n",
    "display(vertex_xyzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "\n",
    "# trimesh.util.attach_to_log()\n",
    "\n",
    "# Material pngs do not seems to be working, either here or in Blender.\n",
    "mesh = trimesh.load(join(ObjectPath, \"transformed.obj\"), skip_materials=True)\n",
    "mesh.show()\n",
    "\n",
    "vertex_point_radius = (mesh.volume / mesh.convex_hull.volume) / 200\n",
    "print(f\"Vertex point size: {vertex_point_radius}\")\n",
    "\n",
    "scene = trimesh.Scene([mesh])\n",
    "for vertex_xyz in vertex_xyzs:\n",
    "    sphere = trimesh.primitives.Sphere(radius=vertex_point_radius, center=vertex_xyz)\n",
    "    scene.add_geometry(trimesh.Trimesh(vertices=sphere.vertices, faces=sphere.faces, face_colors=(255,130,130)))\n",
    " \n",
    "scene.show(smooth=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `micID.npy`\n",
    "\n",
    "From the \"Hardware setup\" secion of the paper:\n",
    "\n",
    "> The gantry system moves a 1.82-meter-tall vertical column of 15 Dayton Audio EMM6 calibrated measurement microphones which are evenly and precisely spaced along the column. It moves this column precisely in two degrees of freedom: azimuth and distance, with a precision of $1\\degree$ and $1 \\text{mm}$, respectively. We suspended a mesh of polyester threads precisely at the axis of rotation of this gantry, centering it vertically along the column of 15 microphones. This mesh holds the objects in place while minimizing contact damping and maximizing the acoustic transparency of the surface holding the object. Furthermore, the layout of the mesh provides visual guidance for precisely positioning the objects in a repeatable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_ids = np.load(join(ObjectPath, \"micID.npy\")) \n",
    "mic_count = len(np.unique(mic_ids))\n",
    "display(mic_ids)\n",
    "print(f\"`mic_ids`:\\n\\tShape: {mic_ids.shape}\\n\\tAll {mic_count} microphone IDs: {np.unique(mic_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot microphone ID for each index.\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(f\"Microphone IDs for first {mic_count * 10} impact samples\")\n",
    "plt.plot(mic_ids[:mic_count*10], 'o')\n",
    "\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Microphone ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `angle.npy` / `distance.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.load(join(ObjectPath, \"angle.npy\"))\n",
    "distance = np.load(join(ObjectPath, \"distance.npy\"))\n",
    "print(f\"`angles`:\\n\\tShape: {angles.shape}\\n\\tUnique values: {np.unique(angles)}\")\n",
    "print(f\"`distance`:\\n\\tShape: {distance.shape}\\n\\tUnique values: {np.unique(distance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "ax[0][0].plot(mic_ids, angles, 'o')\n",
    "ax[0][0].set_title(\"Angle by microphone ID\")\n",
    "ax[0][0].set_xlabel(\"Microphone ID\")\n",
    "ax[0][0].set_ylabel(\"Angle (degrees)\")\n",
    "\n",
    "ax[0][1].plot(mic_ids, distance, 'o')\n",
    "ax[0][1].set_title(\"Distance by microphone ID\")\n",
    "ax[0][1].set_xlabel(\"Microphone ID\")\n",
    "ax[0][1].set_ylabel(\"Distance (mm)\")\n",
    "\n",
    "num_angle_distance_samples = mic_count * 40\n",
    "ax[1][0].plot(angles[:num_angle_distance_samples], 'o')\n",
    "ax[1][0].set_title(f\"Angle for first {num_angle_distance_samples} samples\")\n",
    "ax[1][0].set_xlabel(\"Index\")\n",
    "ax[1][0].set_ylabel(\"Angle (degrees)\")\n",
    "\n",
    "ax[1][1].plot(distance[:num_angle_distance_samples], 'o')\n",
    "ax[1][1].set_title(f\"Distance for first {num_angle_distance_samples} samples\")\n",
    "ax[1][1].set_xlabel(\"Index\")\n",
    "ax[1][1].set_ylabel(\"Distance (mm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `listenerXYZ.npy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener_xyzs = np.load(join(ObjectPath, \"listenerXYZ.npy\"))\n",
    "print(\"`listener_xyzs`:\\n\\tShape: {}\".format(listener_xyzs.shape))\n",
    "display(listener_xyzs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all microphone positions.\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_title('Listener XYZ')\n",
    "ax.set_xlabel('X Pos')\n",
    "ax.set_ylabel('Y Pos')\n",
    "ax.set_zlabel('Z Pos')\n",
    "ax.view_init(elev=65, azim=25)\n",
    "\n",
    "ax.scatter(listener_xyzs[:,0], listener_xyzs[:,1], listener_xyzs[:,2], marker='o', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `deconvolved_0db.npy`\n",
    "\n",
    "`deconvolved_0db.npy` contains 3,000 4-second long audio files recorded at 48 kHz.\n",
    "\n",
    "Each of the 50 recorded objects, were struck from 5 distinct impact positions. Each impact was recorded at 600 field points to provide comprehensive coverage of the frequency components of the sounds and how they are distributed spatially.\n",
    "\n",
    "Total recorded impacts: $5 * 600 = 3,000$ for each object, for a total of 150,000 recorded audio clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleRate = 48_000\n",
    "\n",
    "deconvolved_0db = np.load(join(ObjectPath, \"deconvolved_0db.npy\"))\n",
    "print(f\"`deconvolved_0db`:\\n\\tShape: {deconvolved_0db.shape}\\n\\tObject {ObjectName} has {deconvolved_0db.shape[0]} impact samples with {deconvolved_0db.shape[1]} frames ({(deconvolved_0db.shape[1]/SampleRate):.3f}s) each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "SampleIndex = 0\n",
    "\n",
    "def on_sample_index_change(event):\n",
    "    global SampleIndex\n",
    "    if event['type'] == 'change' and event['name'] == 'value':\n",
    "        SampleIndex = event['new']\n",
    "\n",
    "\n",
    "select_sample_index = widgets.IntText(value=0, description=\"Sample index:\")\n",
    "select_sample_index.observe(on_sample_index_change)\n",
    "\n",
    "display(select_sample_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{ObjectName} impact sample #{SampleIndex}:\\n\\tDistance: {distance[SampleIndex]}mm\\n\\tAngle: {angles[SampleIndex]} degrees\\n\\tMicrophone ID: {mic_ids[SampleIndex]}\")\n",
    "display(Audio(deconvolved_0db[SampleIndex], rate=48000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 3D microphone position for the selected sample.\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_title(f'Selected sample #{SampleIndex} microphone (red) and object (green) position')\n",
    "ax.set_xlabel('X Pos')\n",
    "ax.set_ylabel('Y Pos')\n",
    "ax.set_zlabel('Z Pos')\n",
    "ax.view_init(elev=65, azim=25)\n",
    "\n",
    "ax.scatter(listener_xyzs[:,0], listener_xyzs[:,1], listener_xyzs[:,2], marker='o', alpha=0.15)\n",
    "ax.scatter(0, 0, 0, marker='o', s=50, color='green')\n",
    "ax.scatter(listener_xyzs[SampleIndex,0], listener_xyzs[SampleIndex,1], listener_xyzs[SampleIndex,2], marker='o', s=50, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
